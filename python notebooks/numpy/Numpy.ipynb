{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should familiarize yourself with the `numpy.ndarray` class of python's `numpy` library.\n",
    "\n",
    "You should be able to answer the following questions before starting this assignment. Let's assume `a` is a numpy array.\n",
    "* What is an array's shape (e.g., what is the meaning of `a.shape`)?  \n",
    "* What is numpy's reshaping operation? How much computational over-head would it induce?  \n",
    "* What is numpy's transpose operation, and how it is different from reshaping? Does it cause computation overhead?\n",
    "* What is the meaning of the commands `a.reshape(-1, 1)` and `a.reshape(-1)`?\n",
    "* Would happens to the variable `a` after we call `b = a.reshape(-1)`? Does any of `a`'s attributes change?\n",
    "* How do assignments in python and numpy work in general?\n",
    "    * Does the `b=a` statement use copying by value? Or is it copying by reference?\n",
    "    * Is the answer to the previous question change depending on whether `a` is a numpy array or a scalar value?\n",
    "    \n",
    "You can answer all of these questions by\n",
    "\n",
    "    1. Reading numpy's documentation from https://numpy.org/doc/stable/.\n",
    "    2. Making trials using dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment's main objective is for you to learn how to utilize matrix operations, and avoid manual calculations as much as possible. \n",
    "\n",
    "This objective will have the following benefits:\n",
    " 1. **Efficiency and Scalability**: Utilizing matrix operations will make your code way more efficient for two reasons:\n",
    " \n",
    "    1.1. **Single Processor Speed-Ups**: Using matrix operations can help your processor plan much better for cache placements, and data fetching. Most numerical computation libraries exploit features of efficient cache usage, SIMD features, etc. This can yield enormous speed-ups using the same computational resources.\n",
    "    \n",
    "    1.2. **Multi-Processor Speed-Ups**: Matrix operations are extremely parallelizable. This has a significant impact on hardware acceleration; you could have a parallelizable code without even knowing much about parallelization, as most numerical computation libraries try to automatically exploit as much CPU parallelization as appropriate. \n",
    "    \n",
    "       Furthermore, you could easily use GPU acceleration for the same matrix operations if necessary. On the contrary, it is impractical to convert a python code which was built from scratch using python's default data structures for GPU usage.\n",
    "       \n",
    "    1.3. **Spending Less Time Executing High-Level Language Commands and Out-sourcing the Heavy-lifting to Lower-Level Backends**: The high-level languages tend to have expensive commands, as they prioritize coding convinience over efficiency. However, utilizing matrix operations outsources most of the code's heavy-lifting to lower-level languages without the user even knowing about it. For instance, Numpy runs most operations on a pre-compiled C backend. This is also correct about other numerical evaluation libraries such as the automatic-differentiation libraries (e.g., Tensorflow, PyTorch).\n",
    "    \n",
    "    \n",
    " 2. **Portabiliy**: This will make your code smaller, more understandable, and therefore less prone to have bugs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UC Irvine's Machine Learning Data Repository Department hosts a Kaggle Competition with famous collection of data on whether a patient has diabetes (the Pima Indians dataset), originally owned by the National Institute of Diabetes and Digestive and Kidney Diseases and donated by Vincent Sigillito. \n",
    "\n",
    "You can find this data at https://www.kaggle.com/uciml/pima-indians-diabetes-database/data. The Kaggle website offers valuable visualizations of the original data dimensions in its dashboard. It is quite insightful to take the time and make sense of the data using their dashboard before applying any method to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Information Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Input/Output**: This data has a set of attributes of patients, and a categorical variable telling whether the patient is diabetic or not. \n",
    "\n",
    "* **Missing Data**: For several attributes in this data set, a value of 0 may indicate a missing value of the variable.\n",
    "\n",
    "* **Final Goal**: We want to build a classifier that can predict whether a patient has diabetes or not. To do this, we will train multiple kinds of models, and will be handing the missing data with different approaches for each method (i.e., some methods will ignore their existence, while others may do something about the missing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/dragon/.local/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/dragon/.local/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/dragon/.local/lib/python3.12/site-packages (from seaborn) (3.9.1.post1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/dragon/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dragon/.local/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dragon/.local/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/dragon/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting amlutils\n",
      "  Downloading amlutils-2.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: Pillow>=8.0.1 in /home/dragon/.local/lib/python3.12/site-packages (from amlutils) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.3 in /home/dragon/.local/lib/python3.12/site-packages (from amlutils) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.2.0.34 in /home/dragon/.local/lib/python3.12/site-packages (from amlutils) (4.10.0.84)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/dragon/.local/lib/python3.12/site-packages (from amlutils) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dragon/.local/lib/python3.12/site-packages (from requests>=2.23.0->amlutils) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dragon/.local/lib/python3.12/site-packages (from requests>=2.23.0->amlutils) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dragon/.local/lib/python3.12/site-packages (from requests>=2.23.0->amlutils) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dragon/.local/lib/python3.12/site-packages (from requests>=2.23.0->amlutils) (2024.7.4)\n",
      "Downloading amlutils-2.0.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: amlutils\n",
      "Successfully installed amlutils-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install amlutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'test_case_checker' from 'amlutils' (/home/dragon/.local/lib/python3.12/site-packages/amlutils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mamlutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test_case_checker\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'test_case_checker' from 'amlutils' (/home/dragon/.local/lib/python3.12/site-packages/amlutils/__init__.py)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from aml_utils import test_case_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing the Simplest Classifier Ever!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look above there is a \"Glucose\" level variable in the data. Roughly speaking, a healthy person should never have blood Glucose levels of more than 140mg/liter, since a healthy pancreas should be able to control the glucose level by injecting proper amounts of insulin. Physicians use this fact to design the following simple diabetes diagnosis test, which is called the \"Oral glucose tolerance test\".\n",
    "\n",
    "* Feed the patient an extremely large amount of fast-acting sugar extract.\n",
    "* Test the blood glucose level after a couple of minutes.\n",
    "* If the patient's blood glucose level was less than the 140 mg/liter threshold, then the patient is normal.\n",
    "* If the patient's blood glucose level was in the 140-199 mg/liter range, then the patient is pre-diabetic.\n",
    "* If the patient's blood glucose level was more than 200 mg/liter, then the patient is diabetic.\n",
    "\n",
    "Of course the thresholds are up for debate and research, and this test is not 100% accurate; there are always exceptions and extreme cases. That's why there are many diabetes test types, and we're trying to also build our classifiers which hopefully should be more accurate than this simplistic test. However, this test provides a very simple and memorable way of diabetes assesment and diagnosis.\n",
    "\n",
    "You can read about these tests at https://www.mayoclinic.org/diseases-conditions/diabetes/diagnosis-treatment/drc-20371451#:~:text=If%20it's%20126%20mg%2FdL,for%20the%20next%20two%20hours.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and do our own investigation into how accurate this simplistic test can be. This can serve as a baseline for later comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function ```simple_pred_vec``` that takes a 1-d array of glucose levels $\\mathbf{g}$ and a threshold $\\theta$ as input, and applies the following prediction rule for patient $i$:\n",
    "* Predict 1 (i.e., the patient is diabletic) if the patients glucose level $g_i$ is equal or larger than the threshold (i.e. if $g_i\\geq \\theta$).\n",
    "* Otherwise predict 0 (i.e., the patient is non-diabetic).\n",
    "\n",
    "For this task, the input is a 1-d numpy array $g$ with a shape of $(N,)$ and a scalar value $\\theta$ (where N is the number of patients). Write your function in a way that the output would have exactly the same shape as the $g$ input including any dummy dimensions of 1. The output data type should be boolean.\n",
    "\n",
    "**Note**: You do not need to use any reshaping for this task. In other words, do not reshape the $\\mathbf{g}$ input and do not try to force an $(N,)$ shape on the output array.\n",
    "\n",
    "**Note**: There is no necessity of using any for loops in this task. In fact, iterating over the input manually would be an extremely bad itea; it is both inefficient, and has poor coding portability to various shapes. On the other hand, there is a much better one-liner alternative that out-sources all these required comparisons to be done by Numpy, and is even faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simple_pred_vec(g, theta):\n",
    "    # Apply vectorized comparison to create a boolean array\n",
    "    out = g >= theta\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b624b530ea54b1d6c8c1a7976968d382",
     "grade": false,
     "grade_id": "cell-86cb8c4c039bd74d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_case_checker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (simple_pred_vec(g\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m100.\u001b[39m, \u001b[38;5;241m200.\u001b[39m, \u001b[38;5;241m140.\u001b[39m]), theta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m140.\u001b[39m) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m]))\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m test_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_case_checker\u001b[49m(simple_pred_vec, task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassed\u001b[39m\u001b[38;5;124m'\u001b[39m], test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_case_checker' is not defined"
     ]
    }
   ],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "assert (simple_pred_vec(g=np.array([100., 200., 140.]), theta=140.) == np.array([False, True, True])).all()\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(simple_pred_vec, task_id=1)\n",
    "assert test_results['passed'], test_results['message']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     122
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd27b2a173dc21f71aad5eb77c1ae73b",
     "grade": true,
     "grade_id": "cell-cb0163aee09c60f4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```simple_pred_vec``` function that you previously wrote, write a new function ```simple_pred``` function that takes a pandas dataframe ```df``` and threshold ```theta``` as input, and produces a prediction numpy array `pred`.\n",
    "\n",
    "For this specific task, the `pred` variable will mostly take a shape of $(1, N)$. However, do not force this shape on the `pred` variable by reshaping it to have an exact shape of $(1, N)$; forcing such a shape on the `pred` variable may cause issues when using this function in later tasks.\n",
    "\n",
    "The dataframe ```df``` has a column ```Glucose``` which indicates the blood glucose levels, and a column ```Outcome``` which indicates whether the patient is diabetic or not. You should extract the `Glucose` column from the dataframe and use it for thresholding and prediction.\n",
    "\n",
    "* **Hint**: If you like to have the column ```'des_col'``` of a pandas dataframe ```df``` as a numpy array, then ```df['des_col'].values``` may be helpful.\n",
    "\n",
    "* **Important Note**: The `df['des_col'].values` expression returns a numpy array that is one-dimensional (i.e., has a shape of $(N,)$). In order to maintain portability when possibly utilizing this function in later tasks, it is advised to reshape this `df['des_col'].values` array into having a shape of $(1,N)$ before using it in the `simple_pred` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def simple_pred(df, theta):\n",
    "    # Extract the 'Glucose' column and convert it to a numpy array\n",
    "    glucose_levels = df['Glucose'].values\n",
    "    \n",
    "    # Make predictions using the simple_pred_vec function\n",
    "    pred = simple_pred_vec(glucose_levels, theta)\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1aa83328ef71565a4f7e70bd8ad12c2",
     "grade": false,
     "grade_id": "cell-4b25582b4e3294fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Performing sanity checks on your implementation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(\u001b[43msimple_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m, np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;28;01mTrue\u001b[39;00m]]))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n\u001b[1;32m      5\u001b[0m test_results \u001b[38;5;241m=\u001b[39m test_case_checker(simple_pred, task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "assert np.array_equal(simple_pred(df, 120)[:,:5], np.array([[True, False,  True, False,  True]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(simple_pred, task_id=2)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     20
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bba6b2ca0fe12af6ec5ace6b5531112",
     "grade": true,
     "grade_id": "cell-c2e01e3703208ff8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```simple_pred``` function that you previously wrote, write a new function ```simple_acc``` function that takes a pandas dataframe ```df``` and threshold ```theta``` as input, predicts the `Outcome` label, and returns the accuracy `acc` of the predictor.\n",
    "\n",
    "* In the most trivial case, `theta` can be scalar value (e.g., `theta=120`).\n",
    "\n",
    "* `theta` can also be a column array (i.e., `theta.shape == (k,1)` where `k` could be any integer). In this case, `acc` should be a vector of accuracy values with the same number of elements as `theta`.\n",
    "\n",
    "* `acc` should always be a 1-d numpy array (i.e., `acc.shape == (k,)`). Even if `theta` was a scalar value, `acc` should be a numpy array with the shape `(1,)`.\n",
    "\n",
    "* You can use the exact same way of array extraction (with all the caveats and considerations) from the previous task to extract the `Outcome` column from the `df` dataframe.\n",
    "\n",
    "\n",
    "**<span style=\"color:blue\">Limitation 1</span>** You should not be using any external libraries or functions for implementing this function. Only numpy functions should be used.\n",
    "\n",
    "**<span style=\"color:blue\">Limitation 2</span>** You cannot use any loops, such as ```for``` and ```while```, for implementing this function. You should learn how to implement such basic functionalities using numpy's matrix operations and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Hint**:  Assume that you have a prediction vector ```pred``` and a label vector ```label``` whose shapes are ```(1,N)```. \n",
    "\n",
    "    * Let's have ```a= (pred==label)```. Think about what ```a``` means. \n",
    "    * Can you express the prediction accuracy as a numpy function of ```a```?\n",
    "\n",
    "* **Hint**: Run the following snippet for yourself, and try and make sense of how each of the variables c, d, e, and f were generated given that a and b had different shapes.\n",
    "\n",
    "```Var\n",
    "import numpy as np\n",
    "a = np.array([1,2,3,4]).reshape(1, -1) # \"a\" is a row vector\n",
    "b = np.array([1,3,6]).reshape(-1, 1) # \"b\" is a column vector\n",
    "c = (a == b)\n",
    "d = (a * b)\n",
    "e = (a + b)\n",
    "f = (a > b)\n",
    "print(f'c.shape is {c.shape}. d.shape is {d.shape}. e.shape is {e.shape}. f.shape is {f.shape}.')\n",
    "print('----------')\n",
    "print('c is ')\n",
    "print(c)\n",
    "print('----------')\n",
    "print('d is ')\n",
    "print(d)\n",
    "print('----------')\n",
    "print('e is ')\n",
    "print(e)\n",
    "print('----------')\n",
    "print('f is ')\n",
    "print(f)\n",
    "print('----------')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def simple_acc(df, theta):\n",
    "    \n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb8b43fceef5cdad7c4e98c31d1c1f4f",
     "grade": false,
     "grade_id": "cell-2a75d3ca0ba030c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "\n",
    "# Toy testing the shapes\n",
    "assert simple_acc(df, theta=120).shape == (1,)\n",
    "assert simple_acc(df, theta=np.array([50,100,300]).reshape(3,1)).shape == (3,)\n",
    "\n",
    "# Toy testing the values\n",
    "assert simple_acc(df, theta=120).round(3)==0.698\n",
    "assert np.array_equal(simple_acc(df, theta=np.array([[50,100,20,40]]).T).round(3), [0.352, 0.564, 0.35 , 0.35 ])\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(simple_acc, task_id=3)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e5ae56cad218946e380a81b436ae7ac",
     "grade": true,
     "grade_id": "cell-45466daa662f4547",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function ```best_theta_loopy``` that takes a pandas dataframe ```df```, and uses a ```for``` loop and the function ```simple_acc``` to select the `theta` threshold in the interval $[75,200]$ yielding the highest accuracy.\n",
    "* Both 75 and 200 should be included in the test.\n",
    "* Only search for integer `theta` values.\n",
    "\n",
    "You should produce `best_theta` and `best_accuracy`, where both of them are scalar values.\n",
    "\n",
    "**Note**: In case multiple thresholds yielded the exact same highest accuracy, `best_theta` should be the smallest threshold among them. In other words, in case multiple optima for `theta` existed within the search range, the tie-breaking rule would be to pick the `theta` with the smallest value as `best_theta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def best_theta_loopy(df):\n",
    "    \n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return np.array([best_theta, best_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b5e78551ac58c652dbd6e9bd95e38dc",
     "grade": false,
     "grade_id": "cell-abb5b9dcdba7cc16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "assert np.array_equal(best_theta_loopy(df.iloc[:10, :]), np.array((117, 0.9)))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(best_theta_loopy, task_id=4)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92d19e989164f28f655b38d45f626aa4",
     "grade": true,
     "grade_id": "cell-09fd5da0e516fac4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have implemented this, let's see what the best threshold would be on the whole data set, and what the resulting accuracy would be.\n",
    "\n",
    "We did not perform train/test splits, so the accuracy may be inflated a bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta, best_acc = tuple(best_theta_loopy(df))\n",
    "best_theta, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 5</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of a for loop in the ```best_theta_loopy``` function is unnecessary; you can re-write the function so that it has the same functionality without using any loops.\n",
    "\n",
    "Write a function ```best_theta``` that takes a pandas dataframe ```df```, and uses numpy operations to select the theta threshold in the range $[75,200]$ yielding the highest accuracy. You should again produce both `best_theta` and `best_accuracy` scalars.\n",
    "\n",
    "**Note**: In case multiple thresholds yielded the exact same highest accuracy, `best_theta` should be the smallest threshold among them. In other words, in case multiple optima for `theta` existed within the search range, the tie-breaking rule would be to pick the `theta` with the smallest value as `best_theta`.\n",
    "\n",
    "**<span style=\"color:blue\">Limitation 1</span>** You should not be using any external libraries or functions for implementing this function. Only numpy functions should be used.\n",
    "\n",
    "**<span style=\"color:blue\">Limitation 2</span>** You cannot use any loops, such as ```for``` and ```while```, for implementing this function. You should learn how to implement such basic functionalities using numpy's matrix operations and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def best_theta(df):\n",
    "    \n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return np.array((best_theta, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32c7ef9058cc4c929d7bfbb1f5fce5d1",
     "grade": false,
     "grade_id": "cell-8b1707306c63c8c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "assert np.array_equal(best_theta(df.iloc[:10, :]), np.array((117, 0.9)))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(best_theta, task_id=5)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49917daf78b9c9f126a6aeabed9e1e89",
     "grade": true,
     "grade_id": "cell-44384a1f58bb6e5b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 6</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```simple_pred``` function that you previously wrote, write a new function ```simple_confusion``` function that takes a pandas dataframe ```df``` and threshold ```theta``` as input, and produces the confusion matrix $M$, where the rows correspond to the predicted values and the columns correspond to the actual values. \n",
    "\n",
    "* `theta` is a scalar value.\n",
    "* $M$ should have a shape of $(2,2)$ since there are two classes, and the entries should be integer values.\n",
    "\n",
    "**<span style=\"color:blue\">Limitation 1</span>** You should not be using any external libraries or functions for implementing this function. Only numpy functions should be used.\n",
    "\n",
    "**<span style=\"color:blue\">Limitation 2</span>** You cannot use any loops, such as ```for``` and ```while```, for implementing this function. You should learn how to implement such basic functionalities using numpy's matrix operations and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Hint**: Assume that you have a prediction vector ```pred``` and a label vector ```label``` whose shapes are ```(1,N)```. \n",
    "    * Think about what the matrix ```a=(np.array([0,1]).reshape(2,1) == pred).astype(np.int)``` represents. What is its shape?\n",
    "    * Think about what the matrix ```b=(label.reshape(-1,1) == np.array([0, 1]).reshape(1,2)).astype(np.int)``` represents. What is its shape?\n",
    "    * Think about how you can derive the confusion matrix as a function of ```a``` and ```b```. What matrix operation can be helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def simple_confusion(df, theta):\n",
    "    \n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d48f4644700dd539858819454b72b22e",
     "grade": false,
     "grade_id": "cell-2e6d6c6615fa01f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "assert np.array_equal(simple_confusion(df.iloc[:100, :], theta=144), np.array([[55, 24], [ 8, 13]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(simple_confusion, task_id=6)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19bbb01ea084fe2cdf18e2f5da6a220b",
     "grade": true,
     "grade_id": "cell-e746338238a8c57d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's obtain the confusion matrix and plot the class conditional histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = simple_confusion(df, theta=144)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4), dpi=108)\n",
    "sns.kdeplot(df['Glucose'][df['Outcome']==1].values, ax=ax, label='Diabetic Glucose')\n",
    "sns.kdeplot(df['Glucose'][df['Outcome']==0].values, ax=ax, label='Non-Diabetic Glucose')\n",
    "ax.set_xlabel('Blood Glucose Level (mg/liter)')\n",
    "ax.set_ylabel('Probabilstic Density')\n",
    "ax.set_title('Class-Conditional Histograms for the Glucose Predictor')\n",
    "_=ax.axvline(x=144, c='black', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question to think about is \"why didn't the dashed black separator get placed right at the intersection of the Blue and Orange histograms?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/Numpy/Numpy.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
