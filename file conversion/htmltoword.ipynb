{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 35        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "def extract_text_from_divs(soup):\n",
    "    text = \"\"\n",
    "    # Find all <div> tags containing text\n",
    "    divs = soup.find_all('div')\n",
    "    for div in divs:\n",
    "        # Append text from each <div> tag to the result\n",
    "        text += div.get_text() + \"\\n\"  # Add a newline after each <div> text\n",
    "    return text.strip()  # Strip any leading/trailing whitespace\n",
    "\n",
    "def download_css(css_url):\n",
    "    # Load local CSS file\n",
    "    with open(css_url, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def apply_css_styles(css_code, doc):\n",
    "    # Apply CSS styles to the Word document (if needed)\n",
    "    pass  # You can implement this if you have specific requirements\n",
    "\n",
    "def convert_html_to_docx(html_file, output_docx):\n",
    "    # Load HTML content from file\n",
    "    with open(html_file, 'r', encoding='utf-8') as f:\n",
    "        html_content = f.read()\n",
    "\n",
    "    # Parse HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract text from <div> tags\n",
    "    text = extract_text_from_divs(soup)\n",
    "\n",
    "    # Create a new Word document\n",
    "    doc = Document()\n",
    "\n",
    "    # Add extracted text to the Word document\n",
    "    doc.add_paragraph(text)\n",
    "\n",
    "    # Find and load local CSS file\n",
    "    css_file = os.path.join(os.path.dirname(html_file), 'css', 'style.css')\n",
    "    if os.path.exists(css_file):\n",
    "        css_code = download_css(css_file)\n",
    "        apply_css_styles(css_code, doc)\n",
    "\n",
    "    # Save the Word document\n",
    "    doc.save(output_docx)\n",
    "\n",
    "# Example usage:\n",
    "html_file = 'index.html'\n",
    "output_docx = 'output.docx'\n",
    "convert_html_to_docx(html_file, output_docx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def extract_images(soup, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Find all <img> tags\n",
    "    img_tags = soup.find_all('img')\n",
    "\n",
    "    # Iterate over each <img> tag and copy the image file to the output directory\n",
    "    image_paths = []\n",
    "    for img_tag in img_tags:\n",
    "        # Get the image URL (local file path)\n",
    "        img_url = img_tag.get('src')\n",
    "\n",
    "        # Copy the image file to the output directory\n",
    "        if os.path.exists(img_url):\n",
    "            image_path = os.path.join(output_dir, os.path.basename(img_url))\n",
    "            shutil.copyfile(img_url, image_path)\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def convert_html_to_docx(html_file, output_docx):\n",
    "    # Load HTML content from file\n",
    "    with open(html_file, 'r', encoding='utf-8') as f:\n",
    "        html_content = f.read()\n",
    "\n",
    "    # Parse HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract text from <div> tags\n",
    "    text = \"\"\n",
    "    divs = soup.find_all('div')\n",
    "    for div in divs:\n",
    "        text += div.get_text() + \"\\n\"\n",
    "\n",
    "    # Create a new Word document\n",
    "    doc = Document()\n",
    "\n",
    "    # Add extracted text to the Word document\n",
    "    doc.add_paragraph(text)\n",
    "\n",
    "    # Extract images and add them to the Word document\n",
    "    images_output_dir = os.path.join(os.path.dirname(html_file), 'images')\n",
    "    image_paths = extract_images(soup, images_output_dir)\n",
    "    for image_path in image_paths:\n",
    "        doc.add_picture(image_path)\n",
    "\n",
    "    # Save the Word document\n",
    "    doc.save(output_docx)\n",
    "\n",
    "# Example usage:\n",
    "html_file = 'index.html'\n",
    "output_docx = 'output.docx'\n",
    "convert_html_to_docx(html_file, output_docx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING FONTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "def extract_text_from_divs(soup):\n",
    "    text = \"\"\n",
    "    # Find all <div> tags containing text\n",
    "    divs = soup.find_all('div')\n",
    "    for div in divs:\n",
    "        # Append text from each <div> tag to the result\n",
    "        text += div.get_text() + \"\\n\"  # Add a newline after each <div> text\n",
    "    return text.strip()  # Strip any leading/trailing whitespace\n",
    "\n",
    "def extract_css_styles(css_file):\n",
    "    styles = {}\n",
    "    with open(css_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if '{' in line and '}' in line:\n",
    "                style = line.split('{')[1].split('}')[0].strip()\n",
    "                properties = style.split(';')\n",
    "                for prop in properties:\n",
    "                    if ':' in prop:\n",
    "                        key, value = prop.split(':')\n",
    "                        styles[key.strip()] = value.strip()\n",
    "    return styles\n",
    "\n",
    "def apply_css_styles(styles, element):\n",
    "    if 'font-family' in styles:\n",
    "        element.style.font.name = styles['font-family']\n",
    "    if 'font-size' in styles:\n",
    "        try:\n",
    "            element.style.font.size = Pt(float(styles['font-size'].replace('px', '')))\n",
    "        except ValueError:\n",
    "            pass  # Handle invalid font size\n",
    "\n",
    "def convert_html_to_docx(html_file, output_docx):\n",
    "    # Load HTML content from file\n",
    "    with open(html_file, 'r', encoding='utf-8') as f:\n",
    "        html_content = f.read()\n",
    "\n",
    "    # Parse HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract text from <div> tags\n",
    "    text = extract_text_from_divs(soup)\n",
    "\n",
    "    # Create a new Word document\n",
    "    doc = Document()\n",
    "\n",
    "    # Add extracted text to the Word document\n",
    "    paragraph = doc.add_paragraph(text)\n",
    "\n",
    "    # Extract and apply CSS styles\n",
    "    css_file = os.path.join(os.path.dirname(html_file), 'css', 'style.css')\n",
    "    if os.path.exists(css_file):\n",
    "        styles = extract_css_styles(css_file)\n",
    "        apply_css_styles(styles, paragraph)\n",
    "\n",
    "    # Save the Word document\n",
    "    doc.save(output_docx)\n",
    "\n",
    "# Example usage:\n",
    "html_file = 'index.html'\n",
    "output_docx = 'output.docx'\n",
    "convert_html_to_docx(html_file, output_docx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# images        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def extract_images(soup, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Find all <img> tags\n",
    "    img_tags = soup.find_all('img')\n",
    "\n",
    "    # List to store image paths\n",
    "    image_paths = []\n",
    "\n",
    "    # Iterate over each <img> tag and copy the image file to the output directory\n",
    "    for img_tag in img_tags:\n",
    "        # Get the image source (URL or file path)\n",
    "        src = img_tag.get('src')\n",
    "\n",
    "        # If the image source is a local file path, copy the image to the output directory\n",
    "        if os.path.exists(src):\n",
    "            image_path = os.path.join(output_dir, os.path.basename(src))\n",
    "            shutil.copyfile(src, image_path)\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def extract_text_from_divs(soup):\n",
    "    text = \"\"\n",
    "    # Find all <div> tags containing text\n",
    "    divs = soup.find_all('div')\n",
    "    for div in divs:\n",
    "        # Append text from each <div> tag to the result\n",
    "        text += div.get_text() + \"\\n\"  # Add a newline after each <div> text\n",
    "    return text.strip()  # Strip any leading/trailing whitespace\n",
    "\n",
    "def convert_html_to_docx(html_file, output_docx):\n",
    "    # Load HTML content from file\n",
    "    with open(html_file, 'r', encoding='utf-8') as f:\n",
    "        html_content = f.read()\n",
    "\n",
    "    # Parse HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Create a new Word document\n",
    "    doc = Document()\n",
    "\n",
    "    # Extract text from <div> tags and add it to the Word document\n",
    "    text = extract_text_from_divs(soup)\n",
    "    doc.add_paragraph(text)\n",
    "\n",
    "    # Extract images and add them to the Word document\n",
    "    images_output_dir = os.path.join(os.path.dirname(html_file), 'images')\n",
    "    image_paths = extract_images(soup, images_output_dir)\n",
    "    for image_path in image_paths:\n",
    "        doc.add_picture(image_path, width=Inches(3))  # Adjust width as needed\n",
    "\n",
    "    # Save the Word document\n",
    "    doc.save(output_docx)\n",
    "\n",
    "# Example usage:\n",
    "html_file = 'index.html'\n",
    "output_docx = 'output.docx'\n",
    "convert_html_to_docx(html_file, output_docx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# css images        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
