{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "file_path_ohs = '/home/dragon/Git/Data/ohs-hc-template_v11.xlsx'\n",
    "file_path_nte = '/home/dragon/Git/Data/nte-report-41724.xlsx'\n",
    "\n",
    "# Read the specific sheet from the OHS HC Template file\n",
    "positions_df = pd.read_excel(file_path_ohs, sheet_name='Positions Data Template', engine='openpyxl')\n",
    "\n",
    "# Clean up column names by stripping any leading/trailing whitespace or newline characters\n",
    "positions_df.columns = positions_df.columns.str.strip().str.replace('\\n', '')\n",
    "\n",
    "# Read the NTE REPORT file starting from the second row\n",
    "nte_df = pd.read_excel(file_path_nte, skiprows=1, engine='openpyxl')\n",
    "\n",
    "# Create a new DataFrame with specific columns from positions_df\n",
    "position = positions_df[[\n",
    "    'OHS PIN', 'FY Position Authorization', 'Supervisor PIN',\n",
    "     'Division', 'Branch/Program', 'Position Type',\n",
    "    'Encumbered Position', 'Position Status', 'Employee Status',\n",
    "    'Employee ID', 'Employee Name', 'Preferred Name', 'Position Title',\n",
    "    'Position Description Title', 'Pay Plan', 'Minimum Grade',\n",
    "    'Maximum Grade', 'Career Ladder Position','Hiring Type','Lapse in Appropriations Status',\n",
    "    'Official Workplace Flexibility (Position)', 'Position Clearance','Position DOE Clearance', 'Notes'\n",
    "]].copy()\n",
    "\n",
    "\n",
    "\n",
    "# Add a new column 'Supervisor Role'       \n",
    "position['Supervisor Role'] = position['OHS PIN'].map(position['Supervisor PIN'].value_counts())\n",
    "\n",
    "# Fill NaN values with 0\n",
    "position['Supervisor Role'].fillna(0, inplace=True)\n",
    "\n",
    "# Rearrange columns so 'Supervisor Role' comes immediately after 'Supervisor PIN'                \n",
    "\n",
    "\n",
    "# Function to check if Pay Plan is within position grade range\n",
    "def check_grade_range(row):\n",
    "    try:\n",
    "        pay_plan = float(row['Pay Plan'])\n",
    "        min_grade = float(row['Minimum Grade'])\n",
    "        max_grade = float(row['Maximum Grade'])\n",
    "        \n",
    "        if pay_plan >= min_grade and pay_plan <= max_grade:\n",
    "            return 'Within Position Grade Range'\n",
    "        else:\n",
    "            return 'Outside of Position Grade Range'\n",
    "    except ValueError:\n",
    "        return 'Error: Non-numeric value'\n",
    "\n",
    "\n",
    "# Apply the function to create a new column 'Grade Range Status'\n",
    "position['Grade Range Status'] = position.apply(check_grade_range, axis=1)\n",
    "\n",
    "position = position[['OHS PIN', 'FY Position Authorization', 'Supervisor PIN','Supervisor Role',\n",
    "                     'Division', 'Branch/Program', 'Position Type',\n",
    "                     'Encumbered Position', 'Position Status', 'Employee Status',\n",
    "                     'Employee ID', 'Employee Name', 'Preferred Name', 'Position Title',\n",
    "                     'Position Description Title', 'Pay Plan', 'Minimum Grade',\n",
    "                     'Maximum Grade', 'Career Ladder Position','Grade Range Status','Hiring Type',\n",
    "                     'Lapse in Appropriations Status','Official Workplace Flexibility (Position)', \n",
    "                     'Position Clearance','Position DOE Clearance', 'Notes'\n",
    "                     ]]\n",
    "\n",
    "# Set pandas options to display all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(\"Position DataFrame with rearranged columns and Supervisor Role:\")\n",
    "position\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the file path for the OHS HC Template\n",
    "file_path_ohs = '/home/dragon/Git/Data/ohs-hc-template_v11.xlsx'\n",
    "\n",
    "# Read the 'Vacancy Data' sheet from the Excel file\n",
    "vacancy_df = pd.read_excel(file_path_ohs, sheet_name='Vacancy Data', engine='openpyxl')\n",
    "\n",
    "# Extract specific columns from vacancy_df\n",
    "columns_to_add = [\n",
    "    'Hire Manager', 'HC Servicing Specialists', 'FedHR Navigation Number', \n",
    "    'Nature of Action', 'Current Status', 'Action Owner', 'USA Jobs', \n",
    "    '1. PND PRF Submission', '2. PRF Approved', '3. Budget Certification Complete', \n",
    "    '4. Recruitment Request Submitted to OCHCO', '5. PD Classification Complete', \n",
    "    '6. Recruitment Package Routed to HRMS Staffing POC', '7. Draft Job Analysis Received', \n",
    "    '8. Job Analysis Returned', '9. Draft Vacancy Announcement Documents Received', \n",
    "    '10. Vacancy Announcement Documents Returned', '11. Vacancy Announcement Open', \n",
    "    '12. Vacancy Announcement Closed', '13. Certificate Issued', '14. Certificate Returned', \n",
    "    '15. TJO Issued', '16. Security', '17. FJO Issued', '18. EOD Set or Cancellation Date', \n",
    "    'EOD Set or Cancellation', 'Certificate Expiration Date','Honorific Title', 'Selectee Legal Last Name',\n",
    "    'Selectee Legal First Name', 'Suffix', 'Notes'\n",
    "]\n",
    "\n",
    "# Select only the required columns from vacancy_df\n",
    "additional_data = vacancy_df[columns_to_add].copy()\n",
    "\n",
    "# Concatenate vacancy_df and additional_data horizontally (side by side)\n",
    "vacancy = pd.concat([vacancy_df, additional_data], axis=1)\n",
    "\n",
    "# Convert 'Vacant Date' to datetime format\n",
    "vacancy['Vacant Date'] = pd.to_datetime(vacancy['Vacant Date'], errors='coerce')\n",
    "\n",
    "# Calculate 'Length of Vacancy (Days)'\n",
    "vacancy['Length of Vacancy (Days)'] = (datetime.now() - vacancy['Vacant Date']).dt.days\n",
    "\n",
    "# Extract columns of interest for date calculation\n",
    "date_columns = vacancy.columns[vacancy.columns.str.startswith('1.') & vacancy.columns.str.endswith('Date')]\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "vacancy[date_columns] = vacancy[date_columns].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "# Find the furthest date recorded to the right\n",
    "vacancy['LastDate'] = vacancy[date_columns].max(axis=1)\n",
    "\n",
    "# Calculate the number of workdays between 'LastDate' and today's date, excluding weekends\n",
    "valid_dates = vacancy['LastDate'].notna()\n",
    "vacancy.loc[valid_dates, 'Days in Stage'] = np.busday_count(vacancy.loc[valid_dates, 'LastDate'].values.astype('datetime64[D]'), np.datetime64('today'))\n",
    "\n",
    "vacancy = vacancy[[\n",
    "    'Hire Manager', 'HC Servicing Specialists', 'FedHR Navigation Number', \n",
    "    'Nature of Action', 'Current Status', 'Action Owner', 'USA Jobs', \n",
    "    '1. PND PRF Submission', '2. PRF Approved', '3. Budget Certification Complete', \n",
    "    '4. Recruitment Request Submitted to OCHCO', '5. PD Classification Complete', \n",
    "    '6. Recruitment Package Routed to HRMS Staffing POC', '7. Draft Job Analysis Received', \n",
    "    '8. Job Analysis Returned', '9. Draft Vacancy Announcement Documents Received', \n",
    "    '10. Vacancy Announcement Documents Returned', '11. Vacancy Announcement Open', \n",
    "    '12. Vacancy Announcement Closed', '13. Certificate Issued', '14. Certificate Returned', \n",
    "    '15. TJO Issued', '16. Security', '17. FJO Issued', '18. EOD Set or Cancellation Date', \n",
    "    'EOD Set or Cancellation', 'Certificate Expiration Date','Vacant Date', 'Length of Vacancy (Days)',\n",
    "    'LastDate','Days in Stage','Honorific Title', 'Selectee Legal Last Name','Selectee Legal First Name', \n",
    "    'Suffix', 'Notes'\n",
    "]]\n",
    "\n",
    "# Display the updated DataFrame with the new columns\n",
    "vacancy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path_ohs = '/home/dragon/Git/Data/ohs-hc-template_v11.xlsx'\n",
    "\n",
    "# Read specific sheets into DataFrames\n",
    "individual_data_template = pd.read_excel(file_path_ohs, sheet_name='Individual Data Template')\n",
    "external_detailee_data_template = pd.read_excel(file_path_ohs, sheet_name='External Detailee Data Template')\n",
    "direct_support_ctr_template = pd.read_excel(file_path_ohs, sheet_name='Direct Support CTR Template')\n",
    "positions_data_template = pd.read_excel(file_path_ohs, sheet_name='Positions Data Template')\n",
    "\n",
    "# Extract relevant columns and rename them\n",
    "individual_data = individual_data_template[['Employee ID', 'Honorific Title', 'Employee Legal Last Name', 'Employee Legal First Name', 'Suffix', 'Preferred Name', 'OHS EOD Date', 'Separation Date', 'Reason for Separation', 'Email Address Username', 'Desk Phone', 'Mobile Phone', 'Office Number']].rename(\n",
    "    columns={'Employee ID': 'EmployeeID', 'Honorific Title': 'Honorific Title', 'Employee Legal Last Name': 'Employee Legal Last Name', 'Employee Legal First Name': 'Employee Legal First Name', 'Suffix': 'Suffix', 'Preferred Name': 'Preferred Name', 'OHS EOD Date': 'OHS EOD Date', 'Separation Date': 'Separation Date', 'Reason for Separation': 'Reason for Separation', 'Email Address': 'Email Address', 'Desk Phone': 'Desk Phone', 'Mobile Phone': 'Mobile Phone', 'Office Number': 'Office Number'}\n",
    ")\n",
    "external_detailee_data = external_detailee_data_template[['Detailee ID', 'Honorific Title', 'Detailee Legal Last Name', 'Detailee Legal First Name', 'Suffix', 'Preferred Name', 'Detail EOD Date', 'Detail End Date', 'Email Address', 'Desk Phone', 'Mobile Phone', 'Office Number']].rename(\n",
    "    columns={'Detailee ID': 'EmployeeID', 'Honorific Title': 'Honorific Title', 'Detailee Legal Last Name': 'Employee Legal Last Name', 'Detailee Legal First Name': 'Employee Legal First Name', 'Suffix': 'Suffix', 'Preferred Name': 'Preferred Name', 'Detail EOD Date': 'OHS EOD Date', 'Detail End Date': 'Separation Date', 'Email Address': 'Email Address', 'Desk Phone': 'Desk Phone', 'Mobile Phone': 'Mobile Phone', 'Office Number': 'Office Number'}\n",
    ")\n",
    "contractor_data = direct_support_ctr_template[['Contractor ID', 'Honorific Title', 'Contractor Legal Last Name', 'Contractor Legal First Name', 'Suffix', 'Preferred Name', 'Onboard Date', 'Offboard Date', 'Email Address',  'GFE Mobile Phone', 'Office Number']].rename(\n",
    "    columns={'Contractor ID': 'EmployeeID', 'Honorific Title': 'Honorific Title', 'Contractor Legal Last Name': 'Employee Legal Last Name', 'Contractor Legal First Name': 'Employee Legal First Name', 'Suffix': 'Suffix', 'Preferred Name': 'Preferred Name', 'Onboard Date': 'OHS EOD Date', 'Offboard Date': 'Separation Date', 'Email Address': 'Email Address', 'Desk Phone': 'Desk Phone', 'GFE Mobile Phone': 'Mobile Phone', 'Office Number': 'Office Number'}\n",
    ")\n",
    "\n",
    "# Add missing columns with NaN values for columns not present in some templates\n",
    "external_detailee_data['Reason for Separation'] = pd.NA\n",
    "contractor_data['Reason for Separation'] = pd.NA\n",
    "\n",
    "# Concatenate these DataFrames into a new DataFrame\n",
    "employees_data = pd.concat([individual_data, external_detailee_data, contractor_data], ignore_index=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(\"Employees Data with Employee ID, Honorific Title, Employee Legal Last Name, Employee Legal First Name, Suffix, Preferred Name, OHS EOD Date, Separation Date, Reason for Separation, Email Address, Desk Phone, Mobile Phone, and Office Number:\")\n",
    "employees_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path_ohs = '/home/dragon/Git/Data/ohs-hc-template_v11.xlsx'\n",
    "\n",
    "# Read specific sheets into DataFrames\n",
    "individual_data_template = pd.read_excel(file_path_ohs, sheet_name='Individual Data Template')\n",
    "internal_detailee_data_template = pd.read_excel(file_path_ohs, sheet_name='Internal Detailee Data Template')\n",
    "\n",
    "# Extract Schedule A column from Individual Data Template\n",
    "schedule_a_column = individual_data_template['Schedule A']\n",
    "\n",
    "# Assign Schedule A column to employees_data DataFrame\n",
    "employees_data['Schedule A'] = schedule_a_column\n",
    "\n",
    "# Extract \"Official Workplace Flexibility (Position)\" column from Positions Data Template\n",
    "wpf_status_column = positions_data_template['Official Workplace Flexibility (Position)']\n",
    "\n",
    "# Assign \"Employee WPF Status\" column to employees_data DataFrame\n",
    "employees_data['Employee WPF Status'] = wpf_status_column\n",
    "\n",
    "# Extract \"Pay Plan\" column from External Detailee Data Template\n",
    "pay_plan_detailee = external_detailee_data_template['Pay Plan']\n",
    "\n",
    "# Assign \"Pay Plan\" column to employees_data DataFrame\n",
    "employees_data['Pay Plan'] = pay_plan_detailee\n",
    "\n",
    "\n",
    "# Extract \"Grade\" column from External Detailee Data Template\n",
    "grade_column = external_detailee_data_template['Grade']\n",
    "\n",
    "# Extract \"Detailee Location State\" column from External Detailee Data Template\n",
    "employee_location_state_column = external_detailee_data_template['Detailee Location State']\n",
    "\n",
    "# Assign \"Grade\" and \"Employee Location State\" columns to employees_data DataFrame\n",
    "employees_data['Grade'] = grade_column\n",
    "employees_data['Employee Location State'] = employee_location_state_column\n",
    "\n",
    "# Define a mapping function to clean the city names\n",
    "def clean_city(city):\n",
    "    if city == \"National Capital Region\":\n",
    "        return \"District of Columbia\"\n",
    "    else:\n",
    "        return city\n",
    "\n",
    "# Apply the mapping function to create the \"Location City Clean\" column\n",
    "employees_data['Location City Clean'] = external_detailee_data_template['Detailee Location City '].apply(clean_city)\n",
    "\n",
    "\n",
    "\n",
    "# Extract and rename columns for Security Clearance\n",
    "security_clearance_individual = individual_data_template['Security Clearance'].rename('Security Clearance')\n",
    "security_clearance_external = external_detailee_data_template['Security Clearance'].rename('Security Clearance')\n",
    "security_clearance_ctr = direct_support_ctr_template['Clearance'].rename('Security Clearance')\n",
    "\n",
    "# Extract and rename columns for DOE Clearance\n",
    "doe_clearance_individual = individual_data_template['DOE Clearance'].rename('DOE Clearance')\n",
    "doe_clearance_external = external_detailee_data_template['Security Clearance'].rename('DOE Clearance')\n",
    "doe_clearance_ctr = direct_support_ctr_template['Clearance'].rename('DOE Clearance')\n",
    "\n",
    "# Extract Security Reinvestigation Date from Individual Data Template\n",
    "security_reinvestigation_date = individual_data_template['Security Reinvestigation Date'].rename('Security Reinvestigation Date')\n",
    "\n",
    "# Add these columns to employees_data DataFrame\n",
    "employees_data['Security Clearance'] = pd.concat([\n",
    "    security_clearance_individual, security_clearance_external, security_clearance_ctr\n",
    "], ignore_index=True)\n",
    "\n",
    "employees_data['DOE Clearance'] = pd.concat([\n",
    "    doe_clearance_individual, doe_clearance_external, doe_clearance_ctr\n",
    "], ignore_index=True)\n",
    "\n",
    "employees_data['Security Reinvestigation Date'] = security_reinvestigation_date\n",
    "\n",
    "# Extract columns from External Detailee Template\n",
    "date_not_to_exceed = external_detailee_data_template['Date Not to Exceed'].rename('Date Not To Exceed')\n",
    "home_organization = external_detailee_data_template['Home Organization2'].rename('Home Organization')\n",
    "reimbursable = external_detailee_data_template['Reimbusable'].rename('Reimbursable')\n",
    "\n",
    "# Extract columns from Direct Support CTR Template\n",
    "gfe_mobile_phone_id = direct_support_ctr_template['GFE Mobile Phone ID Number'].rename('GFE Mobile Phone ID Number')\n",
    "gfe_laptop_id = direct_support_ctr_template['GFE Laptop ID Number'].rename('GFE Laptop ID Number')\n",
    "piv_card = direct_support_ctr_template['PIV Card'].rename('PIV Card')\n",
    "contract_end_date = direct_support_ctr_template['Contract End Date'].rename('Contract End Date')\n",
    "\n",
    "# Add these columns to employees_data DataFrame\n",
    "employees_data['Date Not To Exceed'] = date_not_to_exceed\n",
    "employees_data['Home Organization'] = home_organization\n",
    "employees_data['Reimbursable'] = reimbursable\n",
    "employees_data['GFE Mobile Phone ID Number'] = gfe_mobile_phone_id\n",
    "employees_data['GFE Laptop ID Number'] = gfe_laptop_id\n",
    "employees_data['PIV Card'] = piv_card\n",
    "employees_data['Contract End Date'] = contract_end_date\n",
    "\n",
    "\n",
    "# Convert Employee ID to a set for quick lookup\n",
    "employee_ids_on_detail = set(internal_detailee_data_template['Employee ID'].values)\n",
    "\n",
    "# Create Internal Detail column\n",
    "individual_data_template['Internal Detail'] = individual_data_template['Employee ID'].apply(lambda x: 'Yes' if x in employee_ids_on_detail else 'No')\n",
    "\n",
    "# Assuming employees_data already exists and has the structure you want to update\n",
    "# Add the Internal Detail column to employees_data\n",
    "employees_data['Internal Detail'] = individual_data_template['Internal Detail']\n",
    "\n",
    "\n",
    "# Read specific sheets into DataFrames\n",
    "individual_data_template = pd.read_excel(file_path_ohs, sheet_name='Individual Data Template')\n",
    "internal_detailee_data_template = pd.read_excel(file_path_ohs, sheet_name='Internal Detailee Data Template')\n",
    "\n",
    "# Merge to find employees currently on internal detail\n",
    "merged_data = pd.merge(individual_data_template, internal_detailee_data_template, how='inner', on='Employee ID', suffixes=('', '_internal'))\n",
    "\n",
    "# Recreate Internal Detail Location City column\n",
    "employees_data['Internal Detail Location City'] = merged_data['Detail Location City ']\n",
    "\n",
    "# Recreate Internal Detail Location State column\n",
    "employees_data['Internal Detail Location State'] = merged_data['Detail Location State']\n",
    "\n",
    "# Recreate Internal Detail Organization column\n",
    "employees_data['Internal Detail Organization'] = merged_data['Detail Organization']\n",
    "\n",
    "# Recreate Internal Detail EOD Date column\n",
    "employees_data['Internal Detail EOD Date'] = merged_data['Detail EOD Date']\n",
    "\n",
    "# Recreate Internal Detail End Date column\n",
    "employees_data['Internal Detail End Date'] = merged_data['Detail End Date']\n",
    "\n",
    "# Recreate Internal Detail Date Not to Exceed column\n",
    "employees_data['Internal Detail Date Not to Exceed'] = merged_data['Date Not to Exceed']\n",
    "\n",
    "# Recreate Internal Detail Reimbursable column\n",
    "employees_data['Internal Detail Reimbursable'] = merged_data['Reimbursable']\n",
    "\n",
    "\n",
    "# Read specific sheets into DataFrames\n",
    "individual_data_template = pd.read_excel(file_path_ohs, sheet_name='Individual Data Template')\n",
    "external_detailee_data_template = pd.read_excel(file_path_ohs, sheet_name='External Detailee Data Template')\n",
    "direct_support_ctr_template = pd.read_excel(file_path_ohs, sheet_name='Direct Support CTR Template')\n",
    "\n",
    "# Extract Notes columns, ensuring correct column names\n",
    "notes_individual = individual_data_template['Notes'].rename('Notes_Individual')\n",
    "notes_external = external_detailee_data_template['Notes'].rename('Notes_External')\n",
    "\n",
    "# Extract 'Notes ' column from direct_support_ctr_template\n",
    "notes_direct = direct_support_ctr_template['Notes '].rename('Notes_Direct')\n",
    "\n",
    "# Concatenate Notes into a single column in employees_data\n",
    "employees_data['Notes'] = pd.concat([notes_individual, notes_external, notes_direct], ignore_index=True)\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Employees Data with Employee ID, Honorific Title, Employee Legal Last Name, Employee Legal First Name, Suffix, Preferred Name, OHS EOD Date, Separation Date, Reason for Separation, Email Address, Desk Phone, Mobile Phone, Office Number, and Schedule A:\")\n",
    "employees_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the columns for the Off-site CTR Template\n",
    "columns = [\n",
    "    'Contract Assigned', 'Honorific Title', 'Contractor Last Name', \n",
    "    'Contractor First Name', 'Suffix', 'Email Address', 'GFE Mobile Phone', \n",
    "    'GFE Mobile Phone ID Number', 'GFE Laptop ID Number', 'PIV Card', \n",
    "    'Clearance', 'DOE Clearance', 'Onboard Date', 'Offboard Status', \n",
    "    'Offboard Date', 'Notes'\n",
    "]\n",
    "\n",
    "# Create an empty DataFrame with the specified columns\n",
    "off_site_ctr_template = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Display the empty DataFrame\n",
    "off_site_ctr_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming employees_data and positions are already loaded as DataFrames\n",
    "\n",
    "# Extract the required columns from employees_data and rename them\n",
    "separations = employees_data[['EmployeeID', 'Separation Date']].rename(\n",
    "    columns={\n",
    "        'EmployeeID': 'ID',\n",
    "        'Separation Date': 'Date'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Merge separations with positions to get the Employee Status\n",
    "separations = separations.merge(position[['Employee ID', 'Employee Status']], left_on='ID', right_on='Employee ID', how='left')\n",
    "\n",
    "# Drop the redundant Employee ID column from positions\n",
    "separations = separations.drop(columns=['Employee ID'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "separations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming employees_data is already loaded as a DataFrame\n",
    "\n",
    "# Extract the required columns and rename them\n",
    "employee_location = employees_data[['EmployeeID', 'Employee Location State', 'Location City Clean']].rename(\n",
    "    columns={\n",
    "        'EmployeeID': 'ID',\n",
    "        'Employee Location State': 'State',\n",
    "        'Location City Clean': 'City'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the new DataFrame\n",
    "employee_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of months and years\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\"]\n",
    "years = [2024] * len(months)  # All entries are for the year 2024\n",
    "\n",
    "# Create a DataFrame for vacancies over time\n",
    "vacancies_over_time = pd.DataFrame({\n",
    "    \"Month\": months,\n",
    "    \"Year\": years\n",
    "})\n",
    "\n",
    "# Assuming positions DataFrame is already loaded and contains 'Position Status' and 'Date' columns\n",
    "# Example data for positions DataFrame\n",
    "positions = pd.DataFrame({\n",
    "    'Position Status': ['Vacant', 'Filled', 'Vacant', 'Vacant', 'Filled', 'Vacant'],\n",
    "    'Date': pd.to_datetime(['2024-01-15', '2024-02-20', '2024-03-10', '2024-04-25', '2024-05-30', '2024-06-05'])\n",
    "})\n",
    "\n",
    "# Extract month and year from the Date column\n",
    "positions['Month'] = positions['Date'].dt.strftime('%B')\n",
    "positions['Year'] = positions['Date'].dt.year\n",
    "\n",
    "# Filter for the year 2024\n",
    "positions_2024 = positions[positions['Year'] == 2024]\n",
    "\n",
    "# Group by Month and count vacant positions\n",
    "vacancy_counts = positions_2024[positions_2024['Position Status'] == 'Vacant'].groupby('Month').size().reset_index(name='Number of Vacancies')\n",
    "\n",
    "# Merge with vacancies_over_time DataFrame\n",
    "vacancies_over_time = pd.merge(vacancies_over_time, vacancy_counts, on='Month', how='left')\n",
    "\n",
    "# Fill NaN values with 0 (if there are months with no vacancies)\n",
    "vacancies_over_time['Number of Vacancies'] = vacancies_over_time['Number of Vacancies'].fillna(0).astype(int)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "vacancies_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the Excel workbook\n",
    "excel_file_path = '/home/dragon/Git/Data/output_data.xlsx'\n",
    "\n",
    "# Create a Pandas Excel writer using xlsxwriter as the engine\n",
    "with pd.ExcelWriter(excel_file_path, engine='xlsxwriter') as writer:\n",
    "    \n",
    "    # Write each DataFrame to a separate sheet\n",
    "    position.to_excel(writer, sheet_name='Position', index=False)\n",
    "    vacancy.to_excel(writer, sheet_name='Vacancy', index=False)\n",
    "    employees_data.to_excel(writer, sheet_name='Employees Data', index=False)\n",
    "    off_site_ctr_template.to_excel(writer, sheet_name='Off-site CTR Template', index=False)\n",
    "    separations.to_excel(writer, sheet_name='Separations', index=False)\n",
    "    employee_location.to_excel(writer,sheet_name=\"employee_location\", index=False)\n",
    "    vacancies_over_time.to_excel(writer, sheet_name=\"vacancies_over_time\", index=False)\n",
    "print(f\"Data successfully written to {excel_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
