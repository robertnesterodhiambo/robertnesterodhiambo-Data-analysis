---
title: "ML with Different Data sizes"
author: "Frederick Jones"
output:
  html_document: 
    toc: true
date: "`r Sys.Date()`"
---


# DAta Dwonloading and importation



```{r}
# Define the URLs
#urls <- c(
#  "https://excelbianalytics.com/wp/wp-content/uploads/2017/07/1000000%20Sales%20Records.zip",
#  "https://excelbianalytics.com/wp/wp-content/uploads/2017/07/1500000%20Sales%20Records.zip"
#)
#
## Define the filenames to save the zip files locally
#file_names <- c("1000000_Sales_Records.zip", "1500000_Sales_Records.zip")
#
## Download, extract, and import CSV files individually
#for (i in 1:length(urls)) {
#  # Download the zip file
#  download.file(urls[i], destfile = file_names[i], mode = "wb")
#  cat("Downloaded:", file_names[i], "\n")
#  
#  # Extract the downloaded zip file
#  unzip_dir <- paste0("extracted_", i)
#  unzip(file_names[i], exdir = unzip_dir)
#  cat("Extracted to folder:", unzip_dir, "\n")
#  
#  # Get the CSV file path (assuming only one CSV file per ZIP)
#  csv_file <- list.files(unzip_dir, pattern = "\\.csv$", full.names = TRUE)
#  
#  # Import the CSV file into R with a unique data frame name
#  if (length(csv_file) > 0) {
#    df_name <- paste0("sales_data_", i)  # e.g., "sales_data_1", "sales_data_2"
#    assign(df_name, read.csv(csv_file[1], stringsAsFactors = FALSE))
#    cat("Imported CSV file as data frame:", df_name, "\n")
#  } else {
#    cat("No CSV file found in", unzip_dir, "\n")
#  }
#}
## incase above code is not working due to slow internet
library(readr)
sales_data_1 <- read_csv("~/GIT/Data/1000000 Sales Records.csv")
sales_data_2 <- read_csv("~/GIT/Data/1500000 Sales Records.csv")
```

## Dataframe view data1million

```{r}
head(sales_data_1)
```

## Dataframe view Data1.5million

```{r}
head(sales_data_2)
```

### Getting column Names and structure  and summary 

```{r}
colnames(sales_data_1)
str(sales_data_1)
str(sales_data_2)
```

### 1million data Structure


```{r}
summary(sales_data_1)
```


### 1.5 million data Structure

```{r}
summary(sales_data_2)
```

## Data shape 

```{r}
# Get the shape of sales_data_1
shape_sales_data_1 <- dim(sales_data_1)

# Get the shape of sales_data_2
shape_sales_data_2 <- dim(sales_data_2)

# Print the shapes
print(paste("Shape of sales_data_1:", shape_sales_data_1[1], "rows and", shape_sales_data_1[2], "columns"))
print(paste("Shape of sales_data_2:", shape_sales_data_2[1], "rows and", shape_sales_data_2[2], "columns"))

```



# Vizualization


```{r}
sales_data_1
```


### 1. Boxplots


```{r}
library(ggplot2)

# Boxplot for Total Revenue in sales_data_1
ggplot(sales_data_1, aes(x = `Item Type`, y = `Total Revenue`)) +
  geom_boxplot() +
  ggtitle("Boxplot of Total Revenue by Item Type (1M Records)") +
  xlab("Item Type") +
  ylab("Total Revenue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Boxplot for Total Revenue in sales_data_2
ggplot(sales_data_2, aes(x = `Item Type`, y = `Total Revenue`)) +
  geom_boxplot() +
  ggtitle("Boxplot of Total Revenue by Item Type (1.5M Records)") +
  xlab("Item Type") +
  ylab("Total Revenue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### 2. Histograms

```{r}
# Histogram for Total Revenue in sales_data_1
ggplot(sales_data_1, aes(x = `Total Revenue`)) +
  geom_histogram(bins = 50, fill = "blue", alpha = 0.7) +
  ggtitle("Histogram of Total Revenue (1M Records)") +
  xlab("Total Revenue") +
  ylab("Frequency")

# Histogram for Total Revenue in sales_data_2
ggplot(sales_data_2, aes(x = `Total Revenue`)) +
  geom_histogram(bins = 50, fill = "red", alpha = 0.7) +
  ggtitle("Histogram of Total Revenue (1.5M Records)") +
  xlab("Total Revenue") +
  ylab("Frequency")
```

### 3. Heatmaps

```{r}
library(reshape2)


# Calculate the correlation matrix for sales_data_1
cor_matrix_1 <- cor(sales_data_1[, sapply(sales_data_1, is.numeric)], use = "complete.obs")

# Reshape the correlation matrix for heatmap
cor_melted_1 <- melt(cor_matrix_1)

# Heatmap for sales_data_1
ggplot(cor_melted_1, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "red", high = "green", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() +
  ggtitle("Correlation Heatmap (1M Records)")

# Calculate the correlation matrix for sales_data_2
cor_matrix_2 <- cor(sales_data_2[, sapply(sales_data_2, is.numeric)], use = "complete.obs")

# Reshape the correlation matrix for heatmap
cor_melted_2 <- melt(cor_matrix_2)

# Heatmap for sales_data_2
ggplot(cor_melted_2, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "green", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() +
  ggtitle("Correlation Heatmap (1.5M Records)")
```

### 4. Scatterplots
Scatterplots can help visualize relationships between two numeric variables.

```{r}
# Scatterplot for Total Revenue vs. Units Sold in sales_data_1
ggplot(sales_data_1, aes(x = `Units Sold`, y = `Total Revenue`)) +
  geom_point(alpha = 0.5) +
  ggtitle("Total Revenue vs. Units Sold (1M Records)") +
  xlab("Units Sold") +
  ylab("Total Revenue")

# Scatterplot for Total Revenue vs. Units Sold in sales_data_2
ggplot(sales_data_2, aes(x = `Units Sold`, y = `Total Revenue`)) +
  geom_point(alpha = 0.5) +
  ggtitle("Total Revenue vs. Units Sold (1.5M Records)") +
  xlab("Units Sold") +
  ylab("Total Revenue")
```

### 5. Correlation Plots
You can also visualize the correlation matrix using the `corrplot` package.

```{r}
library(corrplot)

# Correlation plot for sales_data_1
corrplot(cor_matrix_1, method = "circle", type = "upper", tl.col = "black", tl.srt = 45, 
         title = "Correlation Plot (1M Records)")

# Correlation plot for sales_data_2
corrplot(cor_matrix_2, method = "circle", type = "upper", tl.col = "black", tl.srt = 45, 
         title = "Correlation Plot (1.5M Records)")
```


# Models

## Data preparation 

```{r}
# Load necessary packages
library(dplyr)


# Convert Order.Date and Ship.Date to Date type
sales_data_1 <- sales_data_1 %>%
  mutate(Order.Date = as.Date(`Order Date`, format="%m/%d/%Y"),
         Ship.Date = as.Date(`Ship Date`, format="%m/%d/%Y"))

sales_data_2 <- sales_data_2 %>%
  mutate(Order.Date = as.Date(`Order Date`, format="%m/%d/%Y"  ),
         Ship.Date = as.Date(`Ship Date`, format="%m/%d/%Y"))

```

### Linear REgresison

```{r}
# Linear regression for sales_data_1
linear_model_1 <- lm(`Total Revenue` ~ `Units Sold`, data = sales_data_1)
summary(linear_model_1)

# Linear regression for sales_data_2
linear_model_2 <- lm(`Total Revenue` ~ `Units Sold`, data = sales_data_2)
summary(linear_model_2)

```


### Perform Multiple linear regression

```{r}
# Multiple regression for sales_data_1
multiple_model_1 <- lm(`Total Revenue` ~ `Units Sold` + `Unit Price` + `Order Priority`, data = sales_data_1)
summary(multiple_model_1)

# Multiple regression for sales_data_2
multiple_model_2 <- lm(`Total Revenue` ~ `Units Sold` + `Unit Price` + `Order Priority`, data = sales_data_2)
summary(multiple_model_2)


```

## Compare Results

```{r}
# Compare the results
cat("Linear Model Summary for Sales Data 1:\n")
print(summary(linear_model_1))

cat("\nLinear Model Summary for Sales Data 2:\n")
print(summary(linear_model_2))

cat("\nMultiple Model Summary for Sales Data 1:\n")
print(summary(multiple_model_1))

cat("\nMultiple Model Summary for Sales Data 2:\n")
print(summary(multiple_model_2))

```

## Logistics Regresison

### Creating binary outputs

```{r}
# Create a binary outcome variable for sales_data_1
sales_data_1 <- sales_data_1 %>%
  mutate(Is_Profitable = ifelse(`Total Revenue` > mean(`Total Revenue`), 1, 0))

# Create a binary outcome variable for sales_data_2
sales_data_2 <- sales_data_2 %>%
  mutate(Is_Profitable = ifelse(`Total Revenue` > mean(`Total Revenue`), 1, 0))

```


```{r}
# Load necessary packages for logistic regression
library(dplyr)
library(caret)  # For confusionMatrix

```


### Model 

```{r}
# Logistic regression for sales_data_1
logistic_model_1 <- glm(Is_Profitable ~ `Units Sold` + `Unit Price` + `Order Priority`, 
                         data = sales_data_1, 
                         family = binomial)

# Logistic regression for sales_data_2
logistic_model_2 <- glm(Is_Profitable ~ `Units Sold` + `Unit Price` + `Order Priority`, 
                         data = sales_data_2, 
                         family = binomial)

```

```{r}
summary
```



####  Models Accuracy 

```{r}
# Predictions for sales_data_1
predictions_1 <- ifelse(predict(logistic_model_1, type = "response") > 0.5, 1, 0)

# Predictions for sales_data_2
predictions_2 <- ifelse(predict(logistic_model_2, type = "response") > 0.5, 1, 0)

# Create confusion matrices to assess accuracy
confusion_matrix_1 <- confusionMatrix(as.factor(predictions_1), as.factor(sales_data_1$Is_Profitable))
confusion_matrix_2 <- confusionMatrix(as.factor(predictions_2), as.factor(sales_data_2$Is_Profitable))

# Display accuracy
accuracy_1 <- confusion_matrix_1$overall['Accuracy']
accuracy_2 <- confusion_matrix_2$overall['Accuracy']

cat("Accuracy for Logistic Regression Model 1:", accuracy_1, "\n")
cat("Accuracy for Logistic Regression Model 2:", accuracy_2, "\n")

```

## KNN
```{r}
mol <- colnames(sales_data_1)
mol
```

```{r}
# Load necessary libraries
library(class)
library(caret)  # For confusionMatrix and other functions


# Preprocess the data for KNN
preprocess_knn <- function(data) {
  # Convert categorical variables to factors if needed
  data$Order.Priority <- as.factor(data$`Order Priority`)
  
  # Create a binary response variable (e.g., profitable or not)
  data$Is_Profitable <- ifelse(data$`Total Profit` > mean(data$`Total Profit`), 1, 0)  # Define profitable
  
  # Select only numeric columns for KNN (including response variable)
  knn_data <- data[, c("Units Sold" , "Unit Price", "Unit Cost" , "Total Revenue", "Total Cost" , "Total Profit" , "Is_Profitable")]
  
  # Scale the data (except for the response variable)
  knn_data_scaled <- scale(knn_data[, -ncol(knn_data)])  # Scale features only
  
  # Bind the scaled features with the response variable
  knn_data_final <- data.frame(knn_data_scaled, Is_Profitable = knn_data$Is_Profitable)
  return(knn_data_final)
}

# Preprocess both datasets
knn_data_1 <- preprocess_knn(sales_data_1)
knn_data_2 <- preprocess_knn(sales_data_2)

# Split the data into training and testing sets (80% train, 20% test)
set.seed(123)  # For reproducibility
train_index_1 <- sample(1:nrow(knn_data_1), 0.8 * nrow(knn_data_1))
train_index_2 <- sample(1:nrow(knn_data_2), 0.8 * nrow(knn_data_2))

train_data_1 <- knn_data_1[train_index_1, ]
test_data_1 <- knn_data_1[-train_index_1, ]

train_data_2 <- knn_data_2[train_index_2, ]
test_data_2 <- knn_data_2[-train_index_2, ]

# Fit KNN Model
k_value <- 5  # You can adjust the value of K

# Predictions for sales_data_1
predictions_1 <- knn(train = train_data_1[, -ncol(train_data_1)], 
                     test = test_data_1[, -ncol(test_data_1)], 
                     cl = train_data_1$Is_Profitable, 
                     k = k_value)

# Predictions for sales_data_2
predictions_2 <- knn(train = train_data_2[, -ncol(train_data_2)], 
                     test = test_data_2[, -ncol(test_data_2)], 
                     cl = train_data_2$Is_Profitable, 
                     k = k_value)

# Evaluate the results
confusion_matrix_1 <- confusionMatrix(as.factor(predictions_1), as.factor(test_data_1$Is_Profitable))
confusion_matrix_2 <- confusionMatrix(as.factor(predictions_2), as.factor(test_data_2$Is_Profitable))

# Print the accuracy
cat("Accuracy for Sales Data 1:", confusion_matrix_1$overall['Accuracy'], "\n")
cat("Accuracy for Sales Data 2:", confusion_matrix_2$overall['Accuracy'], "\n")

```

## Naive Bayes

```{r}
# Install necessary packages if you haven't already
install.packages("e1071")
install.packages("caret")
install.packages("ggplot2")

# Load the libraries
library(e1071)
library(caret)
library(ggplot2)


```

```{r}
# Add Is_Profitable column based on Total.Profit being greater than 0
sales_data_1$Is_Profitable <- ifelse(sales_data_1$`Total Profit` > mean(sales_data_1$`Total Profit`), 1, 0)
sales_data_2$Is_Profitable <- ifelse(sales_data_2$`Total Profit` > mean(sales_data_2$`Total Profit`), 1, 0)

# Convert target variable to factor for both datasets
sales_data_1$Is_Profitable <- as.factor(sales_data_1$Is_Profitable)
sales_data_2$Is_Profitable <- as.factor(sales_data_2$Is_Profitable)

# Split data into train and test sets for both datasets
set.seed(123)  # For reproducibility
trainIndex_1 <- createDataPartition(sales_data_1$Is_Profitable, p = 0.8, list = FALSE)
train_data_1 <- sales_data_1[trainIndex_1, ]
test_data_1 <- sales_data_1[-trainIndex_1, ]

trainIndex_2 <- createDataPartition(sales_data_2$Is_Profitable, p = 0.8, list = FALSE)
train_data_2 <- sales_data_2[trainIndex_2, ]
test_data_2 <- sales_data_2[-trainIndex_2, ]

```

#### Model TRaining

```{r}
# Train Naive Bayes model on both datasets
naive_model_1 <- naiveBayes(Is_Profitable ~ ., data = train_data_1)
naive_model_2 <- naiveBayes(Is_Profitable ~ ., data = train_data_2)

# Make predictions on test sets
predictions_1 <- predict(naive_model_1, test_data_1)
predictions_2 <- predict(naive_model_2, test_data_2)

```

#### Model Evaluation

```{r}
# Confusion matrix and accuracy for sales_data_1
conf_matrix_1 <- confusionMatrix(predictions_1, test_data_1$Is_Profitable)
accuracy_1 <- conf_matrix_1$overall['Accuracy']
print(paste("Accuracy for Dataset 1: ", round(accuracy_1, 4)))
print(conf_matrix_1)

# Confusion matrix and accuracy for sales_data_2
conf_matrix_2 <- confusionMatrix(predictions_2, test_data_2$Is_Profitable)
accuracy_2 <- conf_matrix_2$overall['Accuracy']
print(paste("Accuracy for Dataset 2: ", round(accuracy_2, 4)))
print(conf_matrix_2)

```


```{r}
# Function to plot confusion matrix
plot_confusion_matrix <- function(conf_matrix, title) {
  cm_df <- as.data.frame(conf_matrix$table)
  
  ggplot(cm_df, aes(x = Reference, y = Prediction, fill = Freq)) +
    geom_tile() +
    geom_text(aes(label = Freq), color = "white") +
    labs(title = title, x = "Actual", y = "Predicted") +
    scale_fill_gradient(low = "white", high = "blue") +
    theme_minimal()
}

# Plot confusion matrices for both datasets
plot_confusion_matrix(conf_matrix_1, "Confusion Matrix for Sales Data 1")
plot_confusion_matrix(conf_matrix_2, "Confusion Matrix for Sales Data 2")

```

## Regression Tree

```{r}
library(rpart)
library(rpart.plot)

```


```{r}
# Fit regression tree for the first dataset
reg_tree_1 <- rpart(`Total Profit` ~ ., data = sales_data_1, method = "anova")

# Fit regression tree for the second dataset
reg_tree_2 <- rpart(`Total Profit` ~ ., data = sales_data_2, method = "anova")

```

### Plotting Regression

```{r}
# Plot regression tree for sales_data_1
rpart.plot(reg_tree_1, type = 2, extra = 1, main = "Regression Tree for Sales Data 1")

# Plot regression tree for sales_data_2
rpart.plot(reg_tree_2, type = 2, extra = 1, main = "Regression Tree for Sales Data 2")

```

#### Summary of the models

```{r}
# Summary of the first regression tree model
summary(reg_tree_1)

# Summary of the second regression tree model
summary(reg_tree_2)

```


